{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z053xVLloBnu"
   },
   "source": [
    "Importing and downloading all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40rCBIb3exXi",
    "outputId": "cce3d365-7147-4f20-e4b8-46f5e639dd36"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "print(moviepy.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6w80bDfTfACu"
   },
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI1QK__mChuz"
   },
   "source": [
    "Downloading and unziping the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juLkYWYSfIs8"
   },
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "\n",
    "!wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar\n",
    "!unrar x UCF50.rar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIxGQX-3Cnru"
   },
   "source": [
    "Displaying the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PhV66xgTfIvz",
    "outputId": "33b46fbc-5318-45aa-cd22-26f0363c7d70"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (20, 20))\n",
    "\n",
    "all_classes_names = os.listdir('UCF50')\n",
    "random_range = random.sample(range(len(all_classes_names)), 20)\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
    "\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    plt.subplot(5, 4, counter);plt.imshow(rgb_frame);plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyfT8z3Cb44R"
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "\n",
    "\n",
    "SEQUENCE_LENGTH = 20\n",
    "DATASET_DIR = \"UCF50\"\n",
    "CLASSES_LIST = [\"Punch\",\"PushUps\",\"JugglingBalls\",\"PlayingPiano\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_S0O2gzCrRu"
   },
   "source": [
    "Frame extraction from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIr2u4SYfI1M"
   },
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "\n",
    "    frames_list = []\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        success, frame = video_reader.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnL-btheCuyg"
   },
   "source": [
    "Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E2fiL8FfI3r"
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "\n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "\n",
    "\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "\n",
    "        for file_name in files_list:\n",
    "\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels, video_files_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-0q7_ayfI6U",
    "outputId": "65d2b301-486d-4310-9474-7dbff4529825"
   },
   "outputs": [],
   "source": [
    "features, labels, video_files_paths = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YCBseDHzfI9B"
   },
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz49yw9offLA"
   },
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.25, shuffle = True, random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ht3H7tL2a2D8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8hKsbJAbRI-"
   },
   "source": [
    "Convolutional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ8LIhMUffN-"
   },
   "outputs": [],
   "source": [
    "def create_convlstm_model():\n",
    "    '''\n",
    "    This function will construct the required convlstm model.\n",
    "    Returns:\n",
    "        model: It is the required constructed convlstm model.\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n",
    "                                                                                      IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "    model.add(TimeDistributed(Dropout(0.2)))\n",
    "\n",
    "    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh', data_format = \"channels_last\",\n",
    "                         recurrent_dropout=0.2, return_sequences=True))\n",
    "\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_last'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(len(CLASSES_LIST), activation = \"softmax\"))\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xE0LPpyC19c"
   },
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "yUxuzz3kffQl",
    "outputId": "fc947898-bf70-4fa6-b403-f3e29e38ce78"
   },
   "outputs": [],
   "source": [
    "convlstm_model = create_convlstm_model()\n",
    "\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWkDIjMxC4O_"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OuJTqZqffVk",
    "outputId": "4da96315-198c-4dc1-9ac6-ea371f963c6e"
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "convlstm_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "convlstm_model_training_history = convlstm_model.fit(x = features_train, y = labels_train, epochs = 70, batch_size = 4,shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfOhJuWAcOue"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxWmRgH6ffYk",
    "outputId": "f30fe241-fd56-4c1e-fef7-fe22d0fa5cf1"
   },
   "outputs": [],
   "source": [
    "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss1YEKsiC6jS"
   },
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PstoO8B7ffa9",
    "outputId": "473e3f9c-c9cc-4bee-e872-e512e472d0bf"
   },
   "outputs": [],
   "source": [
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "\n",
    "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "convlstm_model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sklzGyFOC97Z"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lES2S_bUffdY"
   },
   "outputs": [],
   "source": [
    "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
    "\n",
    "    metric_value_1 = model_training_history.history[metric_name_1]\n",
    "    metric_value_2 = model_training_history.history[metric_name_2]\n",
    "\n",
    "    epochs = range(len(metric_value_1))\n",
    "\n",
    "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "    plt.title(str(plot_name))\n",
    "\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "_TZnCSD0xHsD",
    "outputId": "7c99ee35-0638-4dbf-a931-d570fe3202c5"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "2dmKfUqpfff2",
    "outputId": "943ddb8a-8dc8-408d-e5af-cfcc72de431f"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKpT_1vyfI_6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7AdaVb16wKJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKBK1yiGcUC5"
   },
   "source": [
    "LRCN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9FG--nBa6wM_"
   },
   "outputs": [],
   "source": [
    "def create_LRCN_model():\n",
    "    '''\n",
    "    This function will construct the required LRCN model.\n",
    "    Returns:\n",
    "        model: It is the required constructed LRCN model.\n",
    "    '''\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(16, (3, 3), padding='same',activation = 'relu'),\n",
    "                              input_shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(32, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((4, 4))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "    model.add(TimeDistributed(Dropout(0.25)))\n",
    "\n",
    "    model.add(TimeDistributed(Conv2D(64, (3, 3), padding='same',activation = 'relu')))\n",
    "    model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    model.add(LSTM(32))\n",
    "\n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))\n",
    "\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW9egu8qDBPM"
   },
   "source": [
    "Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 858
    },
    "id": "Bmn2EaAw6wP8",
    "outputId": "6062f12c-e77d-4343-bdfb-ac172b041f15"
   },
   "outputs": [],
   "source": [
    "\n",
    "LRCN_model = create_LRCN_model()\n",
    "\n",
    "\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UgcAwjaDEAC"
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RML0HmqS6wU6",
    "outputId": "15fc8b12-bf7c-4310-91cf-d320563b8016"
   },
   "outputs": [],
   "source": [
    "\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "LRCN_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "LRCN_model_training_history = LRCN_model.fit(x = features_train, y = labels_train, epochs = 70, batch_size = 4 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LN5K1cBpCNxn"
   },
   "source": [
    "Saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSL_Stx66wXj",
    "outputId": "de502dd6-9b7a-4a78-802a-4954ece7158c"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "\n",
    "model_file_name = f'LRCN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "LRCN_model.save(model_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VX9ryYVzcXsK"
   },
   "source": [
    "Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "SMVLNYOn6wbC",
    "outputId": "cc0693b6-79f5-4a2e-9692-41aa35691b1f"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(LRCN_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "ZwqL4vOVxbiT",
    "outputId": "76eca1da-6c1e-43a3-cb99-bb12b9c57a7d"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_metric(LRCN_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZseFtBMDIB5"
   },
   "source": [
    "Prediction function for convlstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgTAHQfCxczc"
   },
   "outputs": [],
   "source": [
    "def predict_single_action1(video_file_path, SEQUENCE_LENGTH):\n",
    "\n",
    "    convlstm_model = tf.keras.models.load_model(\"convlstm_model___Date_Time_2025_02_25__00_20_26___Loss_0.2389577180147171___Accuracy_0.9516128897666931.h5\")  # Replace with your file path\n",
    "\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    frames_list = []\n",
    "\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
    "\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        success, frame = video_reader.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    predicted_labels_probabilities = convlstm_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
    "\n",
    "\n",
    "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "\n",
    "\n",
    "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "\n",
    "    print(f'Action Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
    "\n",
    "\n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yS_UpjBtDOhP"
   },
   "source": [
    "Prediction function for LRCN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDifrk6SpehC"
   },
   "outputs": [],
   "source": [
    "def predict_single_action2(video_file_path, SEQUENCE_LENGTH):\n",
    "\n",
    "    LRCN_model = tf.keras.models.load_model(\"LRCN_model___Date_Time_2025_02_25__00_32_17___Loss_0.2389577180147171___Accuracy_0.9516128897666931.h5\")  # Replace with your file path\n",
    "\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    frames_list = []\n",
    "\n",
    "    predicted_class_name = ''\n",
    "\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH),1)\n",
    "\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        success, frame = video_reader.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    predicted_labels_probabilities = LRCN_model.predict(np.expand_dims(frames_list, axis = 0))[0]\n",
    "\n",
    "\n",
    "    predicted_label = np.argmax(predicted_labels_probabilities)\n",
    "\n",
    "\n",
    "    predicted_class_name = CLASSES_LIST[predicted_label]\n",
    "\n",
    "\n",
    "    print(f'Action Predicted: {predicted_class_name}\\nConfidence: {predicted_labels_probabilities[predicted_label]}')\n",
    "\n",
    "\n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9uzIeveDSn7"
   },
   "source": [
    "Testing using convlstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "SprcuOWhxc2L",
    "outputId": "6ec643c5-1c11-4f07-cb82-69bd7938b367"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_video_file_path = f'VID_1.avi'\n",
    "\n",
    "predict_single_action1(input_video_file_path, SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJhwpGXJDXrg"
   },
   "source": [
    "Testing using LRCN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "id": "gDDBeuwzppFx",
    "outputId": "d5655fae-50be-4c52-d5e9-7296818f8f84"
   },
   "outputs": [],
   "source": [
    "\n",
    "predict_single_action2(input_video_file_path, SEQUENCE_LENGTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kuqo7rX2xc4x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ZRfBZZ_xc7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOXGVVKixbqx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
